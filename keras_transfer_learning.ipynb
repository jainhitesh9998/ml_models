{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Overview of Colaboratory Features",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/jainhitesh9998/ml_models/blob/master/keras_transfer_learning.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "j6xn5eQ38GKJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "import logging\n",
        "import sys\n",
        "import numpy as np\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Activation, add, Dense, Flatten, Dropout\n",
        "from keras.layers.convolutional import Conv2D, AveragePooling2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "\n",
        "sys.setrecursionlimit(2 ** 20)\n",
        "np.random.seed(2 ** 10)\n",
        "\n",
        "\n",
        "class WideResNet:\n",
        "    def __init__(self, image_size, depth=16, k=8):\n",
        "        self._depth = depth\n",
        "        self._k = k\n",
        "        self._dropout_probability = 0\n",
        "        self._weight_decay = 0.0005\n",
        "        self._use_bias = False\n",
        "        self._weight_init = \"he_normal\"\n",
        "\n",
        "        if K.image_dim_ordering() == \"th\":\n",
        "            logging.debug(\"image_dim_ordering = 'th'\")\n",
        "            self._channel_axis = 1\n",
        "            self._input_shape = (3, image_size, image_size)\n",
        "        else:\n",
        "            logging.debug(\"image_dim_ordering = 'tf'\")\n",
        "            self._channel_axis = -1\n",
        "            self._input_shape = (image_size, image_size, 3)\n",
        "\n",
        "    # Wide residual network http://arxiv.org/abs/1605.07146\n",
        "    def _wide_basic(self, n_input_plane, n_output_plane, stride):\n",
        "        def f(net):\n",
        "            # format of conv_params:\n",
        "            #               [ [kernel_size=(\"kernel width\", \"kernel height\"),\n",
        "            #               strides=\"(stride_vertical,stride_horizontal)\",\n",
        "            #               padding=\"same\" or \"valid\"] ]\n",
        "            # B(3,3): orignal <<basic>> block\n",
        "            conv_params = [[3, 3, stride, \"same\"],\n",
        "                           [3, 3, (1, 1), \"same\"]]\n",
        "\n",
        "            n_bottleneck_plane = n_output_plane\n",
        "\n",
        "            # Residual block\n",
        "            for i, v in enumerate(conv_params):\n",
        "                if i == 0:\n",
        "                    if n_input_plane != n_output_plane:\n",
        "                        net = BatchNormalization(axis=self._channel_axis)(net)\n",
        "                        net = Activation(\"relu\")(net)\n",
        "                        convs = net\n",
        "                    else:\n",
        "                        convs = BatchNormalization(axis=self._channel_axis)(net)\n",
        "                        convs = Activation(\"relu\")(convs)\n",
        "\n",
        "                    convs = Conv2D(n_bottleneck_plane, kernel_size=(v[0], v[1]),\n",
        "                                          strides=v[2],\n",
        "                                          padding=v[3],\n",
        "                                          kernel_initializer=self._weight_init,\n",
        "                                          kernel_regularizer=l2(self._weight_decay),\n",
        "                                          use_bias=self._use_bias)(convs)\n",
        "                else:\n",
        "                    convs = BatchNormalization(axis=self._channel_axis)(convs)\n",
        "                    convs = Activation(\"relu\")(convs)\n",
        "                    if self._dropout_probability > 0:\n",
        "                        convs = Dropout(self._dropout_probability)(convs)\n",
        "                    convs = Conv2D(n_bottleneck_plane, kernel_size=(v[0], v[1]),\n",
        "                                          strides=v[2],\n",
        "                                          padding=v[3],\n",
        "                                          kernel_initializer=self._weight_init,\n",
        "                                          kernel_regularizer=l2(self._weight_decay),\n",
        "                                          use_bias=self._use_bias)(convs)\n",
        "\n",
        "            # Shortcut Connection: identity function or 1x1 convolutional\n",
        "            #  (depends on difference between input & output shape - this\n",
        "            #   corresponds to whether we are using the first block in each\n",
        "            #   group; see _layer() ).\n",
        "            if n_input_plane != n_output_plane:\n",
        "                shortcut = Conv2D(n_output_plane, kernel_size=(1, 1),\n",
        "                                         strides=stride,\n",
        "                                         padding=\"same\",\n",
        "                                         kernel_initializer=self._weight_init,\n",
        "                                         kernel_regularizer=l2(self._weight_decay),\n",
        "                                         use_bias=self._use_bias)(net)\n",
        "            else:\n",
        "                shortcut = net\n",
        "\n",
        "            return add([convs, shortcut])\n",
        "\n",
        "        return f\n",
        "\n",
        "\n",
        "    # \"Stacking Residual Units on the same stage\"\n",
        "    def _layer(self, block, n_input_plane, n_output_plane, count, stride):\n",
        "        def f(net):\n",
        "            net = block(n_input_plane, n_output_plane, stride)(net)\n",
        "            for i in range(2, int(count + 1)):\n",
        "                net = block(n_output_plane, n_output_plane, stride=(1, 1))(net)\n",
        "            return net\n",
        "\n",
        "        return f\n",
        "\n",
        "#    def create_model(self):\n",
        "    def __call__(self):\n",
        "        logging.debug(\"Creating model...\")\n",
        "\n",
        "        assert ((self._depth - 4) % 6 == 0)\n",
        "        n = (self._depth - 4) / 6\n",
        "\n",
        "        inputs = Input(shape=self._input_shape)\n",
        "\n",
        "        n_stages = [16, 16 * self._k, 32 * self._k, 64 * self._k]\n",
        "\n",
        "        conv1 = Conv2D(filters=n_stages[0], kernel_size=(3, 3),\n",
        "                              strides=(1, 1),\n",
        "                              padding=\"same\",\n",
        "                              kernel_initializer=self._weight_init,\n",
        "                              kernel_regularizer=l2(self._weight_decay),\n",
        "                              use_bias=self._use_bias)(inputs)  # \"One conv at the beginning (spatial size: 32x32)\"\n",
        "\n",
        "        # Add wide residual blocks\n",
        "        block_fn = self._wide_basic\n",
        "        conv2 = self._layer(block_fn, n_input_plane=n_stages[0], n_output_plane=n_stages[1], count=n, stride=(1, 1))(conv1)\n",
        "        conv3 = self._layer(block_fn, n_input_plane=n_stages[1], n_output_plane=n_stages[2], count=n, stride=(2, 2))(conv2)\n",
        "        conv4 = self._layer(block_fn, n_input_plane=n_stages[2], n_output_plane=n_stages[3], count=n, stride=(2, 2))(conv3)\n",
        "        batch_norm = BatchNormalization(axis=self._channel_axis)(conv4)\n",
        "        relu = Activation(\"relu\")(batch_norm)\n",
        "\n",
        "        # Classifier block\n",
        "        pool = AveragePooling2D(pool_size=(8, 8), strides=(1, 1), padding=\"same\")(relu)\n",
        "        flatten = Flatten(name = 'flatten')(pool)\n",
        "        predictions_g = Dense(units=2, kernel_initializer=self._weight_init, use_bias=self._use_bias,\n",
        "                              kernel_regularizer=l2(self._weight_decay), activation=\"softmax\")(flatten)\n",
        "        predictions_a = Dense(units=101, kernel_initializer=self._weight_init, use_bias=self._use_bias,\n",
        "                              kernel_regularizer=l2(self._weight_decay), activation=\"softmax\")(flatten)\n",
        "\n",
        "        model = Model(inputs=inputs, outputs=[predictions_g, predictions_a])\n",
        "\n",
        "        return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mrEFwQFoCPNm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "f8c67b9c-1a24-47d7-8c75-1e3b9ceeebf0"
      },
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Tony607/Keras_age_gender/releases/download/V1.0/weights.18-4.06.hdf5\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-08-31 12:50:39--  https://github.com/Tony607/Keras_age_gender/releases/download/V1.0/weights.18-4.06.hdf5\r\n",
            "Resolving github.com (github.com)... 192.30.253.113, 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/116546625/264bd92e-f3db-11e7-820b-561dd9d2ef00?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20180831%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20180831T125039Z&X-Amz-Expires=300&X-Amz-Signature=90f19b348ee3040dd869384de7272a9eb3392c69b79b3e5d47df0d84c2240504&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dweights.18-4.06.hdf5&response-content-type=application%2Foctet-stream [following]\n",
            "--2018-08-31 12:50:39--  https://github-production-release-asset-2e65be.s3.amazonaws.com/116546625/264bd92e-f3db-11e7-820b-561dd9d2ef00?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20180831%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20180831T125039Z&X-Amz-Expires=300&X-Amz-Signature=90f19b348ee3040dd869384de7272a9eb3392c69b79b3e5d47df0d84c2240504&X-Amz-SignedHeaders=host&actor_id=0&response-content-disposition=attachment%3B%20filename%3Dweights.18-4.06.hdf5&response-content-type=application%2Foctet-stream\n",
            "Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.216.20.195\n",
            "Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.216.20.195|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 195810464 (187M) [application/octet-stream]\n",
            "Saving to: ‘weights.18-4.06.hdf5’\n",
            "\n",
            "weights.18-4.06.hdf 100%[===================>] 186.74M  73.6MB/s    in 2.5s    \n",
            "\n",
            "2018-08-31 12:50:42 (73.6 MB/s) - ‘weights.18-4.06.hdf5’ saved [195810464/195810464]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "g1r69sBB8RXQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2040
        },
        "outputId": "32fc1b9f-6311-43de-f253-6b20be67ca47"
      },
      "cell_type": "code",
      "source": [
        "model = WideResNet(64)()\n",
        "model.summary()\n",
        "model.load_weights('./weights.18-4.06.hdf5')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 64, 64, 16)   432         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 64, 64, 16)   64          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 64, 64, 16)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 64, 64, 128)  18432       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 64, 64, 128)  512         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 64, 64, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 64, 64, 128)  147456      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 64, 64, 128)  2048        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 64, 64, 128)  0           conv2d_19[0][0]                  \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 64, 64, 128)  512         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 64, 64, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 64, 64, 128)  147456      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 64, 64, 128)  512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 64, 64, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 64, 64, 128)  147456      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 64, 64, 128)  0           conv2d_22[0][0]                  \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 64, 64, 128)  512         add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 64, 64, 128)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 256)  294912      activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 256)  1024        conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 256)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 256)  589824      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 256)  32768       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 32, 32, 256)  0           conv2d_24[0][0]                  \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 256)  1024        add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 256)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 256)  589824      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 256)  1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 256)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 256)  589824      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 32, 32, 256)  0           conv2d_27[0][0]                  \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 256)  1024        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 256)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 512)  1179648     activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 512)  2048        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 512)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 16, 16, 512)  2359296     activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 16, 16, 512)  131072      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 16, 16, 512)  0           conv2d_29[0][0]                  \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 512)  2048        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 512)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 16, 16, 512)  2359296     activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 512)  2048        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 512)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 16, 16, 512)  2359296     activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 16, 16, 512)  0           conv2d_32[0][0]                  \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 16, 16, 512)  2048        add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 512)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 512)  0           activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 131072)       0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 2)            262144      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 101)          13238272    flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 24,463,856\n",
            "Trainable params: 24,456,656\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EcmXslwu8i8o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "_k = 8\n",
        "_dropout_probability = 0\n",
        "_weight_decay = 0.0005\n",
        "_use_bias = False\n",
        "_weight_init = \"he_normal\"\n",
        "predictions_r = Dense(units=101, kernel_initializer=_weight_init, use_bias=_use_bias,\n",
        "                              kernel_regularizer=l2(_weight_decay), activation=\"softmax\")(model.layers[-3].output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zoREL8Vb8jlK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2040
        },
        "outputId": "d19ee306-b8e9-4122-8e1b-aac70230c24a"
      },
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 64, 64, 16)   432         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 64, 64, 16)   64          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 64, 64, 16)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 64, 64, 128)  18432       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 64, 64, 128)  512         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 64, 64, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 64, 64, 128)  147456      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 64, 64, 128)  2048        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 64, 64, 128)  0           conv2d_19[0][0]                  \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 64, 64, 128)  512         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 64, 64, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 64, 64, 128)  147456      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 64, 64, 128)  512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 64, 64, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 64, 64, 128)  147456      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 64, 64, 128)  0           conv2d_22[0][0]                  \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 64, 64, 128)  512         add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 64, 64, 128)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 256)  294912      activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 256)  1024        conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 256)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 256)  589824      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 256)  32768       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 32, 32, 256)  0           conv2d_24[0][0]                  \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 256)  1024        add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 256)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 256)  589824      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 256)  1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 256)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 256)  589824      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 32, 32, 256)  0           conv2d_27[0][0]                  \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 256)  1024        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 256)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 512)  1179648     activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 512)  2048        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 512)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 16, 16, 512)  2359296     activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 16, 16, 512)  131072      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 16, 16, 512)  0           conv2d_29[0][0]                  \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 512)  2048        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 512)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 16, 16, 512)  2359296     activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 512)  2048        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 512)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 16, 16, 512)  2359296     activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 16, 16, 512)  0           conv2d_32[0][0]                  \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 16, 16, 512)  2048        add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 512)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 512)  0           activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 131072)       0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 2)            262144      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 101)          13238272    flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 24,463,856\n",
            "Trainable params: 24,456,656\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TZsQ5iYq9V5Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-DedcBUN-rEe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1972
        },
        "outputId": "2c90dabb-c373-4833-8fa3-0e6373d24a95"
      },
      "cell_type": "code",
      "source": [
        "new_model = Model(inputs=model.layers[0].input, outputs= model.layers[-3].output)\n",
        "new_model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 64, 64, 16)   432         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 64, 64, 16)   64          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 64, 64, 16)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 64, 64, 128)  18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 64, 64, 128)  512         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 64, 64, 128)  0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 64, 64, 128)  147456      activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 64, 64, 128)  2048        activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_1 (Add)                     (None, 64, 64, 128)  0           conv2d_3[0][0]                   \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 64, 64, 128)  512         add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 64, 64, 128)  0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 64, 64, 128)  147456      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 64, 64, 128)  512         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 64, 64, 128)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 64, 64, 128)  147456      activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_2 (Add)                     (None, 64, 64, 128)  0           conv2d_6[0][0]                   \n",
            "                                                                 add_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 64, 64, 128)  512         add_2[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 64, 64, 128)  0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 32, 32, 256)  294912      activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 32, 32, 256)  1024        conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 32, 32, 256)  0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 32, 32, 256)  589824      activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 256)  32768       activation_5[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_3 (Add)                     (None, 32, 32, 256)  0           conv2d_8[0][0]                   \n",
            "                                                                 conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 32, 32, 256)  1024        add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 32, 32, 256)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 256)  589824      activation_7[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 32, 32, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 32, 32, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 32, 32, 256)  589824      activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_4 (Add)                     (None, 32, 32, 256)  0           conv2d_11[0][0]                  \n",
            "                                                                 add_3[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32, 32, 256)  1024        add_4[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 32, 32, 256)  0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 16, 16, 512)  1179648     activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 16, 16, 512)  2048        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 16, 16, 512)  0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 16, 16, 512)  2359296     activation_10[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 16, 16, 512)  131072      activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "add_5 (Add)                     (None, 16, 16, 512)  0           conv2d_13[0][0]                  \n",
            "                                                                 conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 16, 16, 512)  2048        add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 16, 16, 512)  0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 16, 16, 512)  2359296     activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 16, 16, 512)  2048        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 16, 16, 512)  0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 16, 16, 512)  2359296     activation_12[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_6 (Add)                     (None, 16, 16, 512)  0           conv2d_16[0][0]                  \n",
            "                                                                 add_5[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 16, 16, 512)  2048        add_6[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 16, 16, 512)  0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 16, 16, 512)  0           activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 131072)       0           average_pooling2d_1[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 10,963,440\n",
            "Trainable params: 10,956,240\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kyUp8D63-44U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c04e24b7-c0f5-4cb0-ba31-ae8a6132b840"
      },
      "cell_type": "code",
      "source": [
        "model.layers[-3]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.Flatten at 0x7ff38fa7e2b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "metadata": {
        "id": "DmauUAYVBJTk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2074
        },
        "outputId": "aed78a48-6a8b-4dc8-edf0-19f4db11c564"
      },
      "cell_type": "code",
      "source": [
        "new_model_1 = Model(model.layers[0].input, [model.layers[-2].output, model.layers[-1].output, predictions_r])\n",
        "new_model_1.summary()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_2 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 64, 64, 16)   432         input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 64, 64, 16)   64          conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 64, 64, 16)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 64, 64, 128)  18432       activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 64, 64, 128)  512         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 64, 64, 128)  0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 64, 64, 128)  147456      activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 64, 64, 128)  2048        activation_14[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_7 (Add)                     (None, 64, 64, 128)  0           conv2d_19[0][0]                  \n",
            "                                                                 conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 64, 64, 128)  512         add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 64, 64, 128)  0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 64, 64, 128)  147456      activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 64, 64, 128)  512         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 64, 64, 128)  0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 64, 64, 128)  147456      activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_8 (Add)                     (None, 64, 64, 128)  0           conv2d_22[0][0]                  \n",
            "                                                                 add_7[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 64, 64, 128)  512         add_8[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 64, 64, 128)  0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 32, 32, 256)  294912      activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 32, 32, 256)  1024        conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 32, 32, 256)  0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 32, 32, 256)  589824      activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 32, 32, 256)  32768       activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_9 (Add)                     (None, 32, 32, 256)  0           conv2d_24[0][0]                  \n",
            "                                                                 conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 32, 32, 256)  1024        add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 32, 32, 256)  0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 32, 32, 256)  589824      activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 32, 32, 256)  1024        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 32, 32, 256)  0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 32, 32, 256)  589824      activation_21[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_10 (Add)                    (None, 32, 32, 256)  0           conv2d_27[0][0]                  \n",
            "                                                                 add_9[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 32, 32, 256)  1024        add_10[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 32, 32, 256)  0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 16, 16, 512)  1179648     activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 16, 16, 512)  2048        conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 16, 16, 512)  0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 16, 16, 512)  2359296     activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 16, 16, 512)  131072      activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_11 (Add)                    (None, 16, 16, 512)  0           conv2d_29[0][0]                  \n",
            "                                                                 conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 16, 16, 512)  2048        add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 16, 16, 512)  0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 16, 16, 512)  2359296     activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 16, 16, 512)  2048        conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 16, 16, 512)  0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 16, 16, 512)  2359296     activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "add_12 (Add)                    (None, 16, 16, 512)  0           conv2d_32[0][0]                  \n",
            "                                                                 add_11[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 16, 16, 512)  2048        add_12[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 16, 16, 512)  0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 16, 16, 512)  0           activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 131072)       0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 2)            262144      flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_9 (Dense)                 (None, 101)          13238272    flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_10 (Dense)                (None, 101)          13238272    flatten[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 37,702,128\n",
            "Trainable params: 37,694,928\n",
            "Non-trainable params: 7,200\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hjR9EMjuDFmo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import cv2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4XISSKVaCBNb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "71fe49fb-19c2-4051-b073-a83e23f06771"
      },
      "cell_type": "code",
      "source": [
        "!wget https://shortpedia.in/images/860x540/r/uploads/2018/07/20/1532077399.jpg"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-08-31 12:53:25--  https://shortpedia.in/images/860x540/r/uploads/2018/07/20/1532077399.jpg\r\n",
            "Resolving shortpedia.in (shortpedia.in)... 43.255.154.35\n",
            "Connecting to shortpedia.in (shortpedia.in)|43.255.154.35|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 85997 (84K) [image/jpeg]\n",
            "Saving to: ‘1532077399.jpg’\n",
            "\n",
            "1532077399.jpg      100%[===================>]  83.98K   129KB/s    in 0.7s    \n",
            "\n",
            "2018-08-31 12:53:27 (129 KB/s) - ‘1532077399.jpg’ saved [85997/85997]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "R9uk0riQDLMH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "65538ab6-c365-4a04-fb74-1295333c26c0"
      },
      "cell_type": "code",
      "source": [
        "image = cv2.imread(\"1532077399.jpg\")\n",
        "img_resize = cv2.resize(image, (64,64))\n",
        "np_image = np.expand_dims(img_resize, 0)\n",
        "np_image.shape\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 64, 64, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "metadata": {
        "id": "ibjl-aBSDqKg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "result = new_model_1.predict(np_image)\n",
        "result_1 = model.predict(np_image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fNNSjsd6EAMQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6bcc89c6-8b24-465c-eb53-41e15e82d5d6"
      },
      "cell_type": "code",
      "source": [
        "predicted_genders = result_1[0]\n",
        "ages = np.arange(0, 101).reshape(101, 1)\n",
        "predicted_ages = result_1[1].dot(ages).flatten()\n",
        "\n",
        "print(predicted_genders)\n",
        "print(predicted_ages)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.02841833 0.9715817 ]]\n",
            "[64.78970789]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "j5zgrEH1EcZ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d5267b8d-aa79-49b4-e814-5ff091e69f86"
      },
      "cell_type": "code",
      "source": [
        "print(predicted_genders)\n",
        "print(predicted_ages)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.02841833 0.9715817 ]]\n",
            "[64.78970789]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_hUjyMsjESzM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "48bad8c5-9d4f-421b-ed92-3495bf12d43b"
      },
      "cell_type": "code",
      "source": [
        "predicted_genders = result[0]\n",
        "ages = np.arange(0, 101).reshape(101, 1)\n",
        "predicted_ages = result[1].dot(ages).flatten()\n",
        "print(predicted_genders)\n",
        "print(predicted_ages)\n",
        "predicted_race = result[2].dot(ages).flatten()"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.02841833 0.9715817 ]]\n",
            "[64.78970789]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "9Q6g9psaEnqT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "94c0e40e-6189-4d48-c51d-987394abeb42"
      },
      "cell_type": "code",
      "source": [
        "print(predicted_race)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[49.9028219]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E1zyiaPsEp4b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}