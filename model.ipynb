{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/jainhitesh9998/ml_models/blob/master/model.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "fqpam2g4ZSzp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Start of import section\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import csv\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Flatten, Dense, Lambda, Conv2D, Activation, Cropping2D, MaxPooling2D, Dropout, Reshape, Convolution2D\n",
        "#from keras.layers import softmax\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import glob\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import math\n",
        "#end of import section\n",
        "#include all the imports within this section."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "512BiQYOZSz4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Implementation The Nvidia end to end driving neural net architecture. \n",
        "#Added a dropout layer after the 1st convolution_layer to  mitigate overfitting\n",
        "#Default drop probablity for any dropout layer added is kept at 0.2.\n",
        "def NvidiaNet(drop_prob = 0.2):\n",
        "    #create a sequential Model\n",
        "    model = Sequential()\n",
        "    \n",
        "    #Add a Cropping layer to trim the unneeded portions of the IMAGE from the feed\n",
        "    #model.add(Cropping2D)\n",
        "    #model.add(Reshape((50,50,3), input_shape=(None,None,3))\n",
        "    model.add(Cropping2D(cropping = ((0, 0), (0,0)), input_shape = (100 ,100 ,3)))\n",
        "    \n",
        "    #Normalization Layer\n",
        "    #model.add(Lambda(lambda X_input: (X_input/255.0 - 0.5)))\n",
        "\n",
        "    #Conv2D Layer 1 with 5 x 5 kernal size\n",
        "    #model.add(Convolution2D(nb_filter = 3, nb_row = 5, nb_col = 5))\n",
        "    model.add(Convolution2D(nb_filter = 3, nb_row = 3, nb_col = 3, subsample=(1,1)))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    #Dropout layer\n",
        "    model.add(Dropout(drop_prob))\n",
        "    \n",
        "    #Conv2D Layer 2 with 5 x 5 kernal size\n",
        "    #model.add(Convolution2D(nb_filter = 24, nb_row = 5, nb_col = 5))\n",
        "    model.add(Conv2D(nb_filter = 24, nb_row = 3, nb_col = 3,subsample=(2,2)))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    #Conv2D Layer 3 with 5 x 5 kernal size\n",
        "    #model.add(Convolution2D(nb_filter = 36, nb_row = 5, nb_col =  5))\n",
        "    model.add(Conv2D(nb_filter = 36, nb_row = 3, nb_col =  3,subsample=(1,1)))\n",
        "    model.add(Activation('relu'))\n",
        "    \n",
        "    #Dropout layer\n",
        "    model.add(Dropout(drop_prob))\n",
        "\n",
        "    #Conv2D Layer 4 with 3 x 3 kernal size\n",
        "    #model.add(Convolution2D(nb_filter = 48, nb_row = 3, nb_col = 3))\n",
        "    model.add(Conv2D(nb_filter = 48, nb_row = 3, nb_col = 3))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    #Conv2D Layer 5 with 3 x 3 kernal size\n",
        "    #model.add(Convolution2D(nb_filter = 48, nb_row = 3, nb_col = 3))\n",
        "    model.add(Conv2D(nb_filter = 64, nb_row = 3, nb_col = 3))\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    #flatten layer\n",
        "    #flatten the output from convolution Layer\n",
        "    model.add(Flatten())\n",
        "\n",
        "    #Fully connected layer 1\n",
        "    model.add(Dense(output_dim = 50))\n",
        "\n",
        "    #Fully connected Layer 2\n",
        "    model.add(Dense(output_dim = 25))\n",
        "\n",
        "    #Fully connected Layer 3\n",
        "    model.add(Dense(output_dim = 10))\n",
        "\n",
        "    #output Layers\n",
        "    model.add(Dense(output_dim = 2, activation='softmax') )\n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YdhtqXeGZS0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938
        },
        "outputId": "995a1d87-08b2-41f1-9363-28c933b6d92e"
      },
      "cell_type": "code",
      "source": [
        "model = NvidiaNet(drop_prob = 0.2)\n",
        "model.summary()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cropping2d_4 (Cropping2D)    (None, 100, 100, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_16 (Conv2D)           (None, 98, 98, 3)         84        \n",
            "_________________________________________________________________\n",
            "activation_16 (Activation)   (None, 98, 98, 3)         0         \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 98, 98, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_17 (Conv2D)           (None, 48, 48, 24)        672       \n",
            "_________________________________________________________________\n",
            "activation_17 (Activation)   (None, 48, 48, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_18 (Conv2D)           (None, 46, 46, 36)        7812      \n",
            "_________________________________________________________________\n",
            "activation_18 (Activation)   (None, 46, 46, 36)        0         \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 46, 46, 36)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_19 (Conv2D)           (None, 44, 44, 48)        15600     \n",
            "_________________________________________________________________\n",
            "activation_19 (Activation)   (None, 44, 44, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_20 (Conv2D)           (None, 42, 42, 64)        27712     \n",
            "_________________________________________________________________\n",
            "activation_20 (Activation)   (None, 42, 42, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 112896)            0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 50)                5644850   \n",
            "_________________________________________________________________\n",
            "dense_14 (Dense)             (None, 25)                1275      \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 10)                260       \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 5,698,287\n",
            "Trainable params: 5,698,287\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=3, strides=(1, 1))`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=24, strides=(2, 2))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=36, strides=(1, 1))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=48)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=64)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=50)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=25)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=2)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "1WCKVmiYZS0Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def list_files(path):\n",
        "    #files = [f for f in listdir(path) if isfile(join(path, f))]\n",
        "    #return files\n",
        "    return glob.glob(path)\n",
        "\n",
        "#Perform horizontal flip and return the image and angles\n",
        "def horizontal_flip(img, angle):\n",
        "    hor_flip = cv2.flip(img, 0)\n",
        "    return hor_flip, -1 * angle\n",
        "\n",
        "def make_square(im, min_size=100, fill_color=(0, 0, 0, 0)):\n",
        "    x, y = im.size\n",
        "    size = max(min_size, x, y)\n",
        "    new_im = Image.new('RGB', (size, size), fill_color)\n",
        "    #print((int((size - x) / 2), int(size - y) / 2))\n",
        "    new_im.paste(im, (int((size - x) / 2), int((size - y) / 2)))\n",
        "    return new_im\n",
        "\n",
        "#Takes a image path as input and reads the corresponding image from the disk present in the ./data path.\n",
        "#converts the image to RGB color model and returns it.\n",
        "def read_image(path):\n",
        "    img = PIL.Image.open(path).convert('RGB')\n",
        "    img = make_square(img)\n",
        "    img = img.resize((100, 100), Image.ANTIALIAS)\n",
        "    #open_cv_image = numpy.array(pil_image) \n",
        "    # Convert RGB to BGR \n",
        "    #open_cv_image = open_cv_image[:, :, ::-1].copy()\n",
        "    #img = cv2.imread(path)\n",
        "    \n",
        "    #img = cv2.resize(img, (100, 100))\n",
        "    #rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    #print(rgb.shape)\n",
        "    return np.asarray(img)\n",
        "\n",
        "\n",
        "#outputs the images and the measurements for the corresponding images persistantly as a subroutine\n",
        "def generator(samples, batch_size = 32): \n",
        "    num_samples = len(samples)\n",
        "    print(num_samples)\n",
        "    while 1: #to run the generator indefinitely, pumping the X, Y sets for the neural network\n",
        "        #shuffle the samples on each EPOCH\n",
        "        sklearn.utils.shuffle(samples)\n",
        "        for offset in range(0, num_samples, batch_size):\n",
        "            batch_samples = samples[offset: offset + batch_size]\n",
        "            \n",
        "            images = []\n",
        "            labels = []\n",
        "\n",
        "            for batch_sample in batch_samples:\n",
        "                \n",
        "                '''\n",
        "                read the image from center camera directly from the disk. \n",
        "                No color model conversion performed for the center image\n",
        "                center image flipped and taken as input irrespective of the center angle.\n",
        "                '''\n",
        "                \n",
        "                name =  batch_sample[0]\n",
        "                image = read_image(name)\n",
        "                images.append(image)\n",
        "                labels.append(batch_sample[1])\n",
        "                #flip_output = horizontal_flip(center_image, center_angle)\n",
        "                #images.append(flip_output[0])\n",
        "                #angles.append(flip_output[1])\n",
        "                \n",
        "                \n",
        "            #Convert the cv2 images and the measurements into numpy array\n",
        "            X_train = np.array(images)\n",
        "            Y_train = np.array(labels)\n",
        "            yield sklearn.utils.shuffle(X_train, Y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qbaHQtI-ZS0Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "outputId": "72eaa6ca-922b-48fe-d052-1f1c9385bf5e"
      },
      "cell_type": "code",
      "source": [
        "#testing\n",
        "def load_trained_model(weights_path):\n",
        "    model = NvidiaNet()\n",
        "    model.load_weights(weights_path)\n",
        "    return model\n",
        "\n",
        "\n",
        "#fishing = load_trained_model(\"./model.h5\")\n",
        "\n",
        "#score = fishing.evaluate(x_test, y_test, batch_size=32)\n",
        "img = read_image(samples[10][0])\n",
        "#prediction = fishing.predict(np.expand_dims(img, axis=0))\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "#print(prediction)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFMCAYAAABCsp4mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJztnWmQHld575/uft933tlHy4w2S7Is\njORYIy+FSdlIGAdjykCCQwXbpRhyc5MLBMeQCimZqBywwy1CbHBBDBeoGPsDF2Jx5SC7cl1Xvr5V\nIiaMRbwgLONNsq1do5E0+7xbL/eDRuf5H9TtOWPPrv/vix719Nt9umfmzPmfZ/OSJEmEEELIm+JP\n9wAIIWQ2wMmSEEIc4GRJCCEOcLIkhBAHOFkSQogDnCwJIcSB3Fv94Fe/+lXZvXu3eJ4nW7ZskfXr\n10/kuAghZEbxlibLX/7yl7J//37ZunWr7Nu3T7Zs2SJbt26d6LERQsiM4S1Nll1dXXLttdeKiMjq\n1aulv79fhoaGpKmpKfV8z/NEROT555+Xzs7OtzjU2Yfr8555PyIimCPQsXiJsf9526PGzuX025bE\nkFOglxFJ8D9oO+DFY56C4zxjXX3JRfLzX71qjgfeoLFb/LKx28u9xq4vv2HsBhkwdqP1LGpGcaOI\niPQXF5pjvZ7ap/yisQdz84wdSx4uqBePPczJUNtLdIcqlgg+efqz7730Ivn3X70oaXgZm1tO+R9x\n1jkwNrhBWKsZ+1M3f8zYx48dhfPTf77Gw7nyu/tm7+ctTZYnTpyQiy++2Px//vz50tPTkzlZPv/8\n87Ju3boxBzMXOdee90NXTc12TD3Yi6fkjmfzkasun6Y7p/PRo0cm9frn2s/yb/OW9yyRsV7imb9I\nSZJYf+XmOq7PO1dWlr9/5eXy2C9+bY7P5ZXlR666XP7tF89KGnNxZXmu/O5O+Mqyo6NDTpw4Yf5/\n/PhxaW9vfyuXIm8X65fdyzg+vl8Qt18o+OW1fowqxmqs6i/sgor+vNQPHdfP1vqNHfk6KZXgWQKw\nozPXr+h9WnOhsUOYIGuNLcYuB3XGjuEPiSf6h8GHx04y5oVEklT7t04ic5C3FDr0nve8R3bs2CEi\nIi+88IJ0dHRkSnBCCJkLvKWV5eWXXy4XX3yx3HzzzeJ5nnz5y1+e6HERQsiM4i3vWf7N3/zNRI6D\nTDPj38tSnerDPluxpvuRxeFjxg6G9PhIeUivEqmcLlnbrAX9LErluHR6vLHuh1YCvV5Ut8zYBa/N\n2NUmleGhhz/2sH+ZZEjs8W7VUYbPSZjBQwghDnCyJIQQByYkdIjMLdCRbilKkKMYXORBqFFQOWns\nfJ/a5ZKGBdVqKr2DCK7kqTfc8jon6u02nuyoao5VPb1eGcbo59UzHjSAAxI84xgi5GV4w/0MWe1l\nRvmMU4fP/YicOQFXloQQ4gAnS0IIcYAy/BzAydONshOUcZzofyIfM18CYxeiPmPn+w/p+f0aiF6J\nVUpXQ7X9GshtOCeG4PYQRH88mr3iRSrZczD4aqJB7tV+DX4vtqmXPKhXGW69G8xQweMZ78/LzLYZ\nH9bls5YvGbkHZOrgypIQQhzgZEkIIQ5Qhs8SrMIVlm2dNa7rZH4S5GgA3uII7MBX26+o9PWG1Otd\nrmrxjAi83rWqFn+QGnrAFfS2V2Er4MzwfSiMEYAcjj24Z79uD8iw2n5dq56P7xIKVPjg4WeMORHh\nypIQQpzgZEkIIQ5Qhp8DOHnDMyq6hZbrVeVzQ62kdumUnlIdMWa5poHj4LwWcHqLWDJfbxyCXQOZ\nnchpL7wX6gU1i1wkn1N53gA3ba0NG3u4plK9CvUvIxT/EIkenQN1HMnYcGVJCCEOcLIkhBAHKMOJ\niNhxznlQo5VApWwsKqsLVS2L5vepDA/KqrHzPgR/hxpkbnnbA/0R9BLQ6hFqdTnrHD+nMjnwVYgn\n8CNdG9F79hzTMXrF84wdF/X8KK+B9lhB3RM9PhlYsfDj/GzyJv8jEwtXloQQ4gAnS0IIcYAyfNYz\nMUnDeJUaeIIDq3MXdk7U4w3zzjf20Ug7LR7cv9fYzSCbfayyjp0b4U4+yHOJoGHZqDyvQaD6UKie\n7l6owu5Dt8i1F1xm7MZ50NQMysVJgGNUcuNUt1kJBNgd0e64qJ+NsyIX8DqSfn0mjU8uXFkSQogD\nnCwJIcQBynAiIraAs4RdYtVrM2YETb9GCipr9yf1xn72sMrgQqQB7R7crWbJS6Uur9evVjQAvlY7\nfZ0qlnzLqbd6JFG789KLjd248kK4BkhvwG61jj3YU08fN1mSPOucN7nQxAyIjAuuLAkhxAFOloQQ\n4gBlODmLzILhcE4AXxisarB6CRqDFZYtN3Y0olK6AqXbKiWV02Gc7uWNrfzx0zLcy0Nge0F/jCsV\nvV4pr1sCsa/yPMEtAS+9Ydlk+5Utj/kk34tMDFxZEkKIA5wsCSHEAcrwWUIcx6m27WGVjOPjE5UY\nGG1JU2hSFoM3urmpxdhrL1xr7MqQSu8DezVA3cfyZ75K4irkY0d4X/iTHo96yT3wxvsJjgvKvMFF\nEusdZLyPzD2H9NPfDpkynHHlMxauLAkhxAFOloQQ4gBl+BwiO6B53MnNaaYk+LcVtHECpdXqGhuN\nvWzFSmP/+plnjR1kyO3EKlSePub8ma0AuH+MnwN5vrh9qbELOS0XN1LFAHm4P94IvhBL+pZGkrHt\nMZUwPn3q4MqSEEIc4GRJCCEOUIbPerJKdIGUjjNOybiK5UnHD+CFsLkYSNMqXKi5Wb3krcUGY5dH\ntIxaPXjYG+BeHnY4s9zRyVljHIFzm4q6DbBqqQbFxzUdO5aFs16HJb1BbsPbCazjcD6Mx58Uaezw\nfaYmn1S4siSEEAc4WRJCiAOU4XMUS7R56dJRLE93eiA6Rrp7mK8NJ+Xz2qu7EEP5tQHtIb4o1qZi\nI2BHNZXQQax/uwMINEf5H43aIfydD8Cl3r5qhbEXLlhg7Eqo+esSgCcfZSzYuIrwwe2dGTOe6VYn\ncwWuLAkhxAFOloQQ4gBl+KwnXRiiF9sud5ZVGgxkOFQez0N5tAL2+65BfvcxrYh+suvXxj7+suaD\nzx9SKd1Y1WvWBD3salpNzaC8mjd6egRNzJp9tRc3t+rlRgaNXayD3uI5KPkGdog595BjDrsDkkh6\njr7tScfnGJssaU81P7PgypIQQhzgZEkIIQ5Qhs92MmOVrWbU6eeg99cH7zKcFPRrT+7hwz3GLh05\nrsfP2B/7PenZpTJcKloRvQ7+LOO9clgFPUN4+qh2R0+py+mPbnNeJXZt/yFjvw73r18439iF1mZj\nNy1bbOxggQbRR9BDPLHeX7poxjHGWZLcQVd7GefEXpZHHhursb7bZMKVJSGEOMDJkhBCHKAMny0k\nfqodx1HKySIJeIhRUuZBthUh57oGVc0HXj1o7Mo+lbXlk73Grg6qPJdQq6Yn0IzMC3RsEWhQX0/P\nDoyHEmxWgPjoc1mKM9aSa35J71k7fFjtbt1CSHIq2wc7jhh7we9cYOyGDg1oz9dr47MQ9bZgkP7Y\nEhjluRePz9dt57CnR8B79J9PKlxZEkKIA5wsCSHEAcrw2QIoLPQax1b5MAj2hoZirVjibEjztXv3\nHjD2yQMqWatHVbIWR1Tioqs2gevHvkrf0AONDVLTg/zqBLYOIi/TnZ9iibqXPZXDIVwDdyXykF+e\nr4Gsr9Pj4SH16h891W/s4opFxl64Sku9NSzu0HFZpewQL9V0UclWqbyMyIVsuU1v+GTClSUhhDjA\nyZIQQhygDJ/B2JW4VXbm4vQA8hgahzX4+q2tP6me61d2/oexKxBY7oV6/SBU6V1BiQt2DWRwDKHX\niZe+RWB5jtGxD1LdqvTtY7C6ckaCouAMQXujdPXhRjFsDySws1AHDc6CYai+/ppGAZwY0EiBZfmi\nng8Di+AdeAGuQRzKu6WebQeoJ1TY047TZHn33XfLM888I2EYyqc//Wnp7OyUzZs3SxRF0t7eLvfc\nc48UCoWxL0QIIbOUMSfLp556Sl599VXZunWr9Pb2yh/+4R/KlVdeKZs2bZLrr79e7r33Xtm2bZts\n2rRpKsZLCCHTwpiT5RVXXCHr168XEZGWlhYplUqya9cuueuuu0RE5JprrpEHHniAk+UkgzHpmPeN\nQekFKK3mjVSM/fyTv9DzD6rXux6aeFXRuw0Se9gKJtd7YX63lQsdpZctizLy00NoNobh3kFG4HUy\nehxfR5TRka2Gx+H5sM95BJo8DznmhUSrv4dHThn72Euv6XVK+o6lUfuSI57deH1MsjzsKMnx1dhN\nyhiUPpl4yThawm3dulWefvpp+fnPfy5dXV0iInLgwAHZvHmzPPTQQ5mf27Nnj6xbt+7tj5YQQqYJ\nZwfPE088Idu2bZMHHnhArrvuOnPcZa7t7Ow053rnUGUU1+e1euTA+2xfvMTY/+Ohnxo7D+1js1eW\n2nPmjR3/rue/oY6LrJVlFVeWwdgry3B0+FseeUC+9vt/Cg+mZubKElIlrZVlcHb7WxF1aGFx4AjG\njssuH5xc6DBKsIgxLNmtlWWgK0vPV7vunad7/Py3u/5SHv3fP9Oxw8rSy6oQ9DZWlgg6kKrgjPvs\nH/+RsY8fO5Y6nrfaLvdc+d19s/fjNFk++eST8r3vfU/uv/9+aW5uloaGBimXy1IsFqW7u1s6OjrG\nvgh5WwQ4YXho6w9wQ6wTzGvPvGDsMnh2GyCPeqisAeo1mEyq8FMRghs2yJB/+ONlSWIMpI/Sc9gx\neB4nsTjGZwTRPXqOVc7NT4+AQy85jh2vDUJaClB9PYYmaAX48In9uo3RB9EE8965Up9jgvp3p2eh\nZ8f7UYRPLmPGWQ4ODsrdd98t3//+96WtrU1ERK666irZsWOHiIg8/vjjsnHjxskdJSGETDNjriwf\ne+wx6e3tlb/6q78yx772ta/JHXfcIVu3bpWlS5fKDTfcMKmDJISQ6WbMyfKmm26Sm2666azjDz74\n4KQMiCi4QxSAJgusk/SssE8bhw2+uM/YefDalkX3MiuwN1kG+VyrgmSG6xegP3hk7TvqZyuW3M7w\nBINMjTIqfXtWsH1ab++MfUHcn7PGiNcAbziI3RAeysdAe9i3DRPdNug7pOXd5q06T2+WGzsxLkuq\nJ1bePx4HoFEabilQh08uTHckhBAHOFkSQogDzA2fwaAkswOs1awraq7ySQg4j49rVfM6CCnCftsx\nCFj0HJcjlZoot6tgoxce5WIlQlmIweTwWXSYYziKj9Iae53jB07bPmxG2GHZIFGtgHDINfcwl1zP\njxLdokB5XsQwJdiiGOjpNnalpJEFuaZGeI50XDzmVvD5mGeTyYYrS0IIcYCTJSGEOEAZPpPBoG4I\nRPfzKkH9msrCk6+8rh/AauQJym3I1EEb8qVL4G0tYekx8CLnrWB1HU8JvMU5+FvsZZQM9zFjBYLq\nxyrvVkuw65mCkt0qcWdJWiwLp8dxjFiCriwayO9FOsaBfo0+GBnSMnitLU16X/g+WBkwGCRvSfJ0\n4T73c2dmPlxZEkKIA5wsCSHEAcrwGYyXEaQdgHc77tYmW9ExLSXWVKdFIUoVlYgow0OQ3jWQ3iPg\nDS+DHEUPdA2CofNQxq0GQekJlnfDhmWgOrHJGlZNt2uNwzmjHvMoo383XhulvHW9DNeyVZwDth8q\n4D1HOTw4rBXUq6F60rFnu1U9jsxquLIkhBAHOFkSQogDlOGzBahAngcx2Pu6ll+LetU7G+ax4RcE\nXoOOxDzuCujXEP3IKI1BU3oZlcxRdyYQoB5jnUkouRaDnEb5GluNzEDLRqc/i0Hx1liwmpvlcoYh\nWjUjMbgethxg2wC9+hHkfYc1aOwG/dglTt8WyCY9n91LDwiga3ya4MqSEEIc4GRJCCEOUIbPZEDD\n+ShjQd727zto7AIEh0d+uqyugqStWrnnWDYtPafbUoKo1EF2YoA1Vnf3/CD1HKssG0pyDEQHT/0Z\n53wMud5+Lj1qwPPwei5l0zAAH66PUh3GIn76cSvoXdKfNXsM6RXo7UB+rnGmA751QghxgJMlIYQ4\nQBk+g0FJloNuh+VjPcYeOnnC2MUC5IBHWh0d88rLEIheBVlYwcByrCqOsjqPgeXpdpyke6ZtTWl1\nPlM7szQ4Hk7O+lgIkQI5CJz3sKNj+uUs0Etv3xNslMlQsj5fr90d4wwpTSf27IYrS0IIcYCTJSGE\nOEAZPoPBsmJF8Cafek094PGIBkNj1e9qogHTJSitVgKJWIowTzzDa2vJ5Cx5CfIfPMoBeG2xb7ef\nUfVdUhuTpZOgOx63BCBSwIvR057lZVbsXHy8GTQ1s7z92Mwt/VfJy/CAZ1VKz8pbt6PVrS9kfIBM\nNFxZEkKIA5wsCSHEAcrwGQx6Z5OqSub+4yeNXbCCt/WcGjYgAxk5ApK8fsE8Yzfk9Efh8BFtfJYH\njzIGXlueYwgmjwTzzeH8WM/PQ/A8Ni9DDYpK07ek7Gk7S6Zjfrd1aYcK5Fll3GL/7PuLiBSgDF6x\noUHPmIxOY3SlTztcWRJCiAOcLAkhxAHK8BkMyrkQ88FLWvkc+2snEHBeARmegCs6gT7jV37oA8b+\n9W9e0Hsd1bJveShJVguxx7ZeP8BSbCDDE4zahvNjDOaGv9dwWIKs8mRnruGll4vDCALcKYhAx/p4\nT6vUG3wWtgoEEgIEtiW8gsrwBM7JLl+XfpjMDriyJIQQBzhZEkKIA5ThMxj0OPed0sZkA4Mqw+NI\nG2XFoQaio1wsgxe77bzzjL107Vpj/+rF38BH00ueYek2y9Mcp0tNq1wanp8pQdMzqa2SZ97Zx0CR\ni4dV0LFQOsptKwBf5bOlkuGdRdCwrBLpO87nNR88l8vr+bAFguXdsgLRyeyAK0tCCHGAkyUhhDhA\nGT6D8UFKD5e0R3V3f5+eU9Hc8BgakBVA/o2ApFy+ZJGeX1QZ2dK6AO6bXtXcFpEoz8FrD5I8B/oY\n+4OL5T2HwHX02sNn0cNtmprBYHyr5Bt4xqHUnAfudXyvgdWQDZ8VGpbBuDzIpw+gQjvaVmV3rkfm\nDPxOEkKIA5wsCSHEAcrwGQx6VVvnax63FPTbNjCg3vAA5GJNPyoheIIbmhr1CyBHiw14HH4sUFLa\nJcP1FJThGUHhXlb1cC9DHlsl3eC2o/9i9fckTpfPVsk3O+IcR5B6HCMRcOwo1Rta9J3VQbB/CZua\nTTZ0sE8ZXFkSQogDnCwJIcQByvAZDHpV65vqjd3Y2mTs/pPHjI2lzBIILEcZe3L/AWPX+geM3Tav\n1di5nOY8e1VtfIaVwX38M5tgwLcexspmmMOOEe05DICHkm62bMbGY6eP23/l0yusJ/DgORijn3H/\nAALLLa8+3KwAkQIh5MHj+R6ONx6fTs6qrJ4FVfjUwZUlIYQ4wMmSEEIcoAyfyYDnFUulNbc16yng\nMUdNFvnp3tzjB7XZWX+P9h9fuHChsYvgMQ9PqAy3WoIn6YHXOfQiR+hJR0+z2ip8f6vNOMpa6096\nMnq99A/GGSXRfLg/Sm8cLwbOW1sIAchqeN3lSg1sTRrIF3XLhI3D5w5cWRJCiAOcLAkhxAHK8BkM\nlvTK+SpYlyxbYewX//M5/YCHweTpgdS1igaxD/RqjvkFFy019sKODmMfOtpt7CCfLkfR6+z5KLF1\nPOiNtgPRYfiW9zyrh/fo57J6m3vpUQB1UIqtDjzaBTjuQxK6FWgPdgAB+/lAc+uDIH1DIcmKhbeg\nT3s2wJUlIYQ4wMmSEEIcoAyf0ahuq0L5tSUrVIYXW1qMHQ9ruTar7zV4fEtVleE9J7X/+AUgsRct\nWmzsg7JHr4Mj87L+zuqNrQZkcNz30j3jWd5iDNROUs5ByY4NyAJ4CbmMMm4ogKMQmrBBgHoA8rwY\n6K/MAihrFwQayB9ZgfnjdYFTks9UuLIkhBAHOFkSQogDlOEzGFRwlVDlcz2UButYBpL5lZeNnUsg\nwBqkYwwasTw4pDcA9bd4mXrGC1B6rBrrGCyPtiV9oX826nYIYrdlMASxO0RtnzkDHeCBlZetdhHG\nks/wnkcZJeKw+roP/c+LHkQltGvUQA76htegmrq1Ghm3JCczCaeVZblclmuvvVb+9V//VY4ePSqf\n+MQnZNOmTfL5z39eqrAHRgghcxWnyfK73/2utLaerkrzT//0T7Jp0yb58Y9/LCtXrpRt27ZN6gAJ\nIWQmMKYM37dvn+zdu1fe9773iYjIrl275K677hIRkWuuuUYeeOAB2bRp06QO8twlPUg6X2ww9vIL\nVhv79ZdAhoPii1AWghoOatBQDDzBrfPajN3Yonno5b4Ten4OfN0og63xW03EU230dGeVJ/NSvOeB\nlfetz1G0As4xP17t2HLAY544bFdY0h5eGuS7x6G+1wQbmWVVYp8UpvJe5zZeMkbn90996lPyd3/3\nd7J9+3ZZtmyZ3HPPPdLV1SUiIgcOHJDNmzfLQw899KY32bNnj6xbt27iRk0IIVPMm64st2/fLpde\neqksX7489etjzLOGzs5Oc/54i5vOZlyf14ojhHfavmiJsb/zw4eN3VavK8vnR/9wiYj8+2OPGbuI\nBWjh21SB1dAlv3uFsa/+gw8Zu++4xl8+9j//xdgncWUJ1/dHV2E/+dm/ySev/gNzvA5XsRhniYWJ\nYYXqsrI8YwdwbR9We8UgY2UJUZ8xpljCSjSXQMoiLoqh6lB1NP7yy49+V374zR+a482dusKv4Xid\nVnu4Mh/7dwrfRwiK4C8/caOxe7qPpp7v+jt71gjPkd/dN3s/bzpZ7ty5Uw4ePCg7d+6UY8eOSaFQ\nkIaGBimXy1IsFqW7u1s6II+YTB4xJGPXoCzb4qXquW5uBck8pJ5uT+dHCWByOHbwiLFP9uhE2Naq\nzdEaW7Qqew9UZRe4DhQMt3qXJzBZxVbTL/Ce60czpwlLaI5eB73POT8jBx2rtcFFYg+ld/oflQgm\nVGyeFsEfm4FT+kdlQfwOPcfqc57+INbYhMwG3nSy/OY3v2ns++67T5YtWybPPfec7NixQz760Y/K\n448/Lhs3bpz0QRJCyHQz7qD02267TbZv3y6bNm2Svr4+ueGGGyZjXIQQMqNwDkq/7bbbjP3ggw9O\nymDIb5PuZQ5BCi6AwOj5C9uNvb+v39gF+DZjSnfP8ePGPnhAG5kt/F3dK21doPnP/uuv6XUyGnGh\n3A5hLzEPshnbanugWbHvOT6w3cN79Fzcs8zIHUevNx6PMMs9qYGNWwjp403goj0HdV+wFbYx6hZp\n1XncAwus4ID0Mft++volzuhFTgk/dTDdkRBCHOBkSQghDjA3fJaAYRsxBGH7eQ13yUFIUYIeZ5B2\nAUjQGGTygRdeMfYFF60x9uKV5xn7xV/vNnaIaa5+RsiPf3bIj4jtDbcamaGmxNzvlLzurDAWcMxb\nvccTeGf4/iKILMDGazEEqEfgsy9AKbahXvWGH967z9gXdqgMD2E5YpVu89O3HLKw3h9Kddw6oCif\nVLiyJIQQBzhZEkKIA5ThsxCsfB6BPJvXrt5wP1+AD6iZgFcVM1y639B+4kdf3mvs5kYtB1eo02vW\nRrRPtgeyMLFc3SgX4TAGf1vno9SE4cM5Zzzf6GWOLPEN1waJj+dgBo/VhA3zx/GlwWBqAjngsBVx\nEt5Zx9Jlxp5/gWa/VT3cAlEvfASB/FV4VnxufF6U4Vj1K8nwmJOJgStLQghxgJMlIYQ4QBk+S0BP\nJ9qVRGVhx3lQ4bxRPeO14WFjY+OuCNyz1RFtdrbvhReMfcmllxi7qUlzz0u9GvSOVcXRsWs7t/F/\n6WPATyRW8Qw9IxqVo1bjsiT92khkLQsgcN5q7JZu53Bcsb5vDMCvDQwY+zgE79fN03c2GKlkxsQC\njEqohSrPs4o6oGccJTx6+cnEw5UlIYQ4wMmSEEIcoAyfhVittsEz2twGFc7btJ/48cFeY9fDdVBG\n5vL6o3Dw0GFjL16yBOxFxj51TMu1YdmyGFzdVdgikATy0zFfGhuWeekivgZeZH/0fM8KhM+q16i2\n5VnGnHsoNYeebpTtcQ7Hq/eqeCqZY9gX6O/V9+2/ccjYIz7mnqN3W99NkNMb53LwzjIqymNJPMak\nTy5cWRJCiAOcLAkhxAHK8BkNSi9ovwB/4zCou7Gl1djLVq4w9kCvlg+TkgaTRxDQ7EN5tBhaFfzq\nuV8Zuw7bQWQEQKNHFtKurUD0AHKtMe8bm4QlmFceYwD66PUz/szHGVoUtxzQYW7liXvojccA9XTw\nTjj2wVN9xi7M16iB/AL1jKO3vVDUYH+U3lbgPchtq795Rkk3MvHwTRNCiAOcLAkhxAHK8JmMFV+N\nXmM9GoFUA6Uul7373cae36by/Bc7/5+xc8U6vQ5KYLjXYKUEdsXY+Yyq3+gVRod1DUqJWT28Mkq3\n+eBI9/zkLLuGEj+jDzkSYT49lqkD25L+KIFr6EkHeQ5a2koUgAD/vpO6BbIIZHgtxkD0MNVGGY4N\n2nywJcNLTiYeriwJIcQBTpaEEOIAZfhMxkp5Tvfmoq8WPbKFZu33fXRAPbIl8Hp7cINyBQKssXo4\nSMG6PHjkUfJVVTp64M0NIc8Z74XB6jXIi87Bj2MBgsV98AR7o9LXw8/l0huy4T0jDHJHjz2eA+8P\ntxAK2GwNPPkhBLFjGbc41iiD0pC++7qiVrVvbYOmZkF6dADiB1DtHt4NRi54Htc+kwnfLiGEOMCV\n5SzBs6P69DgcTmDJWbMq+Oi32YceMsN92kOmVlPnTUODFvzFu1axqg2sdIoFvSYujIKMSkl4EqzN\nrD45eCtsdXsm3REL3eZxMWY5qjCGEzxCWKwY6xNjBSI4XsEYR3jhVlwoFu2F9Mygqs6ePNxgKaSR\nRpLuKMIBZfXgiWpQjDjg2mcy4dslhBAHOFkSQogDlOGzBky6g5hLPAUlMGz2d3auMza2bz1iVaxR\nuxBo/GUM0q4CDpt3Lj/f2KUejSWsgSzMZ5QCtusC6XNVQXaGWHwX2/SM9tLBmEjccsAqPNgC2BNM\nF1Ww+HCE4Ytwz1xGq1+sZCRYvQirJIFs7zl61Nh5iH1tbldnTz6ACkQOqYxYvYitcCcXriwJIcQB\nTpaEEOIAZfisISOVDVP90BugDnpsAAAgAElEQVQOvWKa5s8z9rs2vMfYB5dpz54IJHZjg8Zo1kO8\nJqbcnT9f2+4+8dNHjI1VfLCwrmT0k8HjWIkntFISlTP9fqwCvuDSRlkaWkV+wdMOnmWU8xGkVQZW\nQWH9bJjgtgFIfqxSBO9ppKIxl6++/IqxXzmsRYEvWN9p7EvXa8+jLLJ685DJhStLQghxgJMlIYQ4\nQBk+S0iswGWwLYczBm+n96hZ0KF9dOa3d6ScYaf6CXp8Qf5hgHVr+wL9LBavDUGSwzWzWuT6GI+N\n7WFRTo9KXEtKe3gf8IBbahVlO/a/AQkP52N6JG4DeHDRGlZ/grMicKtX4cNxTbc6qlAgeAja6GIA\nvksrXDrApw6uLAkhxAFOloQQ4gBl+IwmSTUt0YzJzdizJ+M6cYRVitK7y1iSHD8LnuB8vQau55sa\njJ3D8YAzHPOoMc8dR4+jCUCCWh7r0bNikNtWcSarEjB4t+Ek3KKIIiviPXUsuNWB1y9h5DpcJ4TK\nTlicGXPSI7DL5bKx+3pVnre0ajvj7F47WT8jZKLhypIQQhzgZEkIIQ5Qhs8axqexss72HHq2+Em6\nPE8y7IY2lYvoFc7B5X1B2ZzRXBZLt1le57Pt0OrpA4WCk3SvdynDg2zlX3uZby11jANQYA698AFc\nB4sUW7nbOR3zkf0HjX10yXnGbgYZnoWXlaxAJhyuLAkhxAFOloQQ4gBl+IwmXf6Nl6zg5iwPq6VG\nMYA7wwPdOq9Nz6nTPjNxVYOwE8gTr2IwN0Sih+CdD+1QcDg++i98DmV9kqRHBMR2cx4db8Zywc+Q\n7fjcFeg9jC1yc/ACc5ZHXq+J5eti6H+EvXbyeX2XIQS0Z3vGyWTCt04IIQ5wsiSEEAcow+cobyc+\nOcmS/BAcjtcvNmoZt2JLs7FP9p4yNjY7K4EXOYFGYjFIa/TyYq76mS0FjKePIQg8S25ji1lrmwFj\n0q188/TrWN7njJeM7XWxZBwuTbBNcDDO38KsKAYyuXBlSQghDnCyJIQQByjDZwuYK23Z1kkTdLN0\nL7xVwgyd1XXaNzxsLBq775RKzRA+HGGF8QQlNNgo+dF7PZp7HoAnGnU6Vjj3sa+3lYSO5dfAc52D\naucZOd2SEfQunj6TB9fH8u94L0vyRxA1APsLfobczv7+k8mEK0tCCHGAkyUhhDhAGT6TSS92Pm2g\nYzcGeZkvaLk2DD6vQA9vD13a2NwrI+Ibq6an7S5Y18vYiogtL7ak/sezbj+2prUrtGec46CNUYZj\n6buRoSFj+1b1uAxJzrpsUwZXloQQ4oDTyvLRRx+V+++/X3K5nHzuc5+TNWvWyObNmyWKImlvb5d7\n7rlHCoXC2BcihJBZypiTZW9vr3znO9+Rhx9+WEZGRuS+++6THTt2yKZNm+T666+Xe++9V7Zt2yab\nNm2aivGeW2R6wNPtLCYsiDklOFxExAfpjV5kD7zImM+M1cmtPuMZ47R2I97io2Q2/wow+ByaneFn\nx3vNjKZjWXYYapB+X59WSo9gG2O833My8Ywpw7u6uuTKK6+UpqYm6ejokK985Suya9cuef/73y8i\nItdcc410dXVN+kAJIWQ6GXNleejQISmXy/KZz3xGBgYG5LbbbpNSqWRk94IFC6Snp+dNr/H888/L\nunXrROTc+6t4rj3v//rR/dM9hCmj64nHpnsIFjceOzqp1z/XfpZ/G6c9y76+Pvn2t78tR44ckU9+\n8pPjlgSdnZ3m3HMpr9X1ebNkW/uixca+74fbjJ3D3txvQ4a/ne8FlmurVEoiInLTdRvlw390izl+\nDH55UZJjT/BYwGOedS+rJJk3eixIP3mcZFaOt5z3Zwuwricekyuv/dCY18TvVRBARXe4ZhXKr629\n6GJjX//hjxgbK9D7cJ0YpPqtf/xxY/d0H0sdz1ud8M6V3903ez9jyvAFCxbIZZddJrlcTlasWCGN\njY3S2NhoOtJ1d3dLR0fHxI2WEEJmIGNOlhs2bJCnnnpK4jiW3t5eGRkZkauuukp27NghIiKPP/64\nbNy4cdIHSggh08mYMnzRokXywQ9+UG688UYREbnjjjuks7NTbr/9dtm6dassXbpUbrjhhkkf6DkP\nRk97Y0Rsn0X6Ock4I91RoqAiC2P15kZQck3A0xxgIDpEc+P5ttd78iSf5enOkl0YIJ8xlKz+Ztbp\neH2MIIBTsI95AQL8MTccc/HRS85m4VOH057lzTffLDfffLN17MEHH5yUARFCyEyEGTyEEOIAc8Nn\nDVnS2yGfOfML4+xFjmXW4nRJnodybSgj0fubYM/vxIp0H9d4xoMlmUFX243JsMI5VoVPr+CO4OWt\nRmkRllyDtQk489Fj3gq9wtF7Xq1V9XhBG5lZknzuO6unFa4sCSHEAU6WhBDiAGX4OUaW99f2dGcE\namecnwtUFhabtHlZDFW/sa+2pMd+T6pfN7Fd4GCqjcVgLHmLgQhZrnHrZmqizMcq6EmM709/DYv1\n9caOvQz5j98fq4r72EMjbx2uLAkhxAFOloQQ4gBl+Kxh7FJfExXI7SLVUWKjfO1cv97Yr736KnwW\nvMIgHa0mZdgMPEOgT3iJNrjgmjVrjI2l0o4cOZI6xsx3n1FNPfN8CN4fGNZK6RUo3YYN15Jo7Hx6\nMvFwZUkIIQ5wsiSEEAcow2cLM9jTifndq9/xDmNfsPoCY7/26j5jq+/8t4K5M0qkIW81bh2vjZXa\nm1vUe3/Fu99t7JGREWP/4hf/YeyBgUEdC24PJBhBkDVIbFKm52CxOWxYhuXXcOsCg9VjzMUnkwpX\nloQQ4gAnS0IIcYAyfJYQgRfWs7zGSlZF7DjjfBdcKmtHNfXa1oFnHGVt97FuY6PUtJqEBel/uy0v\nctoxp2r02DxNz29oUBne2jbf2PMXLjT2FaFWMh8eKRn7kksvNfbeV/YauzoybOwcPh/ct2iVr9Nx\nxtWKsfv6eo29YIGOx24cJ2SK4MqSEEIc4GRJCCEOUIbPFkBuYd7yRAWiv50cbUv+Q87zqpXnG/t3\n1q419n/+cpd+FhqPuVQt10Njy3AMCMfyaLVEZXW+TiuTo5cZtwRWrlpt7AiC69+5TpuLjQyr9/zA\nG+r5D0B658GjXQfa2wd7CLztfQMaGN+2ULcIrFx1RqVPGVxZEkKIA5wsCSHEAcrwGUwIucHVStnY\nTS1aTRsleZKRWu3i0c7KynYBr47XqQOJu3zlSmM/99xzen5GrrXl7fbT3L94p/S/+VaPNysHXb/Q\n3NRs7ABkcgRvIcLqcnn19reCNF55vj5febDf2P29p1Kvjy8NgxVqVf1+DvWpJK8MqRe+sbEh7TJk\nkuHKkhBCHOBkSQghDlCGz2BKZZXeu3/1K2Nf/q53GTsPfaYTyHnG3ljZedZZja/HK8TTc56x1/Wi\nJYuN3QRNufpOaeD1ROBlNCDDLQ083r6oQz+bg6x1aKoWgMc+BM1cB+++Y0G7sQcXLzX2UL96tDNT\nxmFbYKSkAe09xzWQf9myZcauBxlOpg6uLAkhxAFOloQQ4gBl+AwGxfDLL75k7FOn1MO69qKLjL1y\nhXpksYlYlCX/MiuJZXXBziI9QLwGOdUt4MFvbWsz9vGeHmPnoXGXh97wtDbpuM+A94ToAPR6n3fe\nCmOvXqsV0det79TPxirVI7gpNh3zYG8h8HS8jfPmGbt5nnrJ88Wijqeq2yriwR4FPKtf0/FXB9Ub\nXoJg9SpsY2CVejK5cGVJCCEOcLIkhBAHKMNnMA0N6vVcd7HmIb/w4m+M3XXypLF73nHM2O9co7nY\nbSAL4zRJe9Z/Mv6GeulyG4V6gMHf8IUCBHMvW7LE2G+89rqxc5CbjTI7sILLTx9PrP7damOZteWr\ndFviinddYex57VruzM/prwB6zCN4UYmPZdYwl11HUNfYaOym+TqGInwPB8tami6EvZGCr+8mh1sK\n0Lys95R+n9s61POOHnl2L5tcuLIkhBAHOFkSQogDlOEzGGxS1XmZVuVeuHiRsffs2WPsV/dpabDj\nJ04Y+3fAY75suXqF8xiEjRHkmMM8TmmXWPXDsDq5/qitgDH8umG3fhY94CCDAxjEGc90OVLJ3Nis\n1c4//vEbjd0EudsYq44SOA4hkB/vYyXXj909Dc9oqFfp3Viv8nwEJDyWjAvAxhJ31bJWTS9BBXWs\nB2BDHT6ZcGVJCCEOcLIkhBAHKMNnMChLa9WqsTFPuA0CvPfu1aZZb7z+mrF/+ctfGvuiQfWwvmO1\n9viur9fg6URQ5qV7nfGonQ+OHvP0c7AZWCsEWA8P6NgKOZWsOTl7WyCq6vUamlTqNs9r1XP99GB1\nDCZHiZ1gUziU2OCkR5mcVV0ee3mjt9qHC2GfcewPHuPxmgb1l6BRWrWqx9EjTxE+uXBlSQghDnCy\nJIQQByjDZwkosSIIni7WqXxes0ZznhcsWGDsF/Y8D7Z6zwcGtKL3xevWGRtlcpzh8XUBJWINJG5L\nq24dtLaobK5CNfCiVS4NLjqq7TFSoA68zxhAblVhB2c/Nh3DQPgkceivjg+FgesQsI+V7IvQlzzI\n6/dKwJuPd43hf/jYlYp6wyuwJeNSBZ9MDFxZEkKIA5wsCSHEAcrwGQxKLGyghRI0xIZlICkXL9Nq\n3c2NKgV/84Lmle8/sN/YfQMDxu4ESb7svOXGDnL44zJ2326rSVio4yxAKTbMf0evsEAQu/28p+Ur\n5rg3t6qUtzzzEHAewD3RTR+BHMbHiNAzDuPKYQA5vAMrsz6vWwiNMLZiozZHG+rXCvF5uG8Oty5q\nOrawpOXd4grKcIetAzIhcGVJCCEOcLIkhBAHKMNnMFagM8gtlIiJ7So2Vg0Cl+vBW3z55ZcZu61N\nJeIr+zSg/XnwmJdK6qFetXKVsfNQoTvO7MQFQIC4DwHnGFCO3mt8XmzEFo82EvMh8NtPLzouUYxV\n0/V4ANsVuIGAJdpiy8sMNnw2QsmPQe+BrkHw+RqhjFtpULc9EvSAg8zHwHjJ8HpjPjv94pMLV5aE\nEOIAJ0tCCHGAMnwGYwWiZ3hnER+rh2c08cJzLnin5oY3zddA8Zd+o83R9h84aOwAAsWXLtVq53XQ\nlCvLM+5nhLRjrjU2GLOOQw9vkzptlTJTT3EInuLYquwON8UObpgbnqDch7FjtTaU9vBe8foeeO+b\noHxcSwt4w3u18nkZeoVjIjrKatxSKJd1awS3DrLePZkYuLIkhBAHOFkSQogDlOEzGBfvJgauZ9mo\nIxMMFAdp3N6uTbCa3q3S8dhRbYI2DHLx+Ant970cKp+jd1YygrytSt8wtiyPv60uTz8XBqoP9vUZ\ne2REx1gET7QVRC8o8fE+Xuo5do/v9DJ1iRXoDgH4dVqiDZuX1TfUG7tW0W0EDCzIUtUBVFy3pDfz\nxCeVMSfL4eFhuf3226W/v19qtZrceuut0t7eLnfeeaeInC7ecNddd032OAkhZFoZc7L86U9/KqtW\nrZIvfOEL0t3dLX/yJ38i7e3tsmXLFlm/fr184QtfkJ/97Gdy9dVXT8V4CSFkWhhzspw3b568/PLL\nIiIyMDAgbW1tcvjwYVm/fr2IiFxzzTXS1dXFyXKG4ZKvbTUI89JLnq264AJjnzylTdDsHtvgIYYA\na9/Ko0aJreNBT7otIvV/IeRvnzmKYx8eVuk9NKTV1uubswLe9S6WlLZiwNPLryXQDB2D0jFw3kvS\nc9Lrm3R7o1DUd+wFg3pjeK9WGTooxYfS3q7WThk+mXiJQ0G8P/uzP5MDBw7IwMCAfPe735W///u/\nl+3bt4uISFdXl2zbtk2+8Y1vZH5+z549sg6KMxBCyGxjzJXlI488IkuXLpUf/OAH8tJLL8mtt94q\nzc0aL+ZSfLSzs9Ocey7Fgrk+b9Zqb357h7H/+3f+2dg5qP6D5+NK5LfHMda98LNYxwavmLWyXLrk\ndIWj//KR6+Rf/u/P0q+JlXvg+NNPPWXsp3Y+aeymvKZTRvHZK0vs9ZOHNMLf+9D1xm5foi2DcWXp\nw1Nl9tGxHGRqeqMryz+94YPywPb/A5+Fdwwry7Ciaafdhw8Z+xC0LT55vFs/iymXMLp5UP3poku0\nLfLS87Qf0+f/6yZj9xxTx1zW93w8nCu/u2/2fsacLJ999lnZsGGDiIisXbtWKpWK9YvS3d0tHR0d\nWR8nb4P0VmFvD5w0Mo/DZOZDnvOiDp18ShUNjPYClKY6KZYgWDzvY9cvlJcqKQPIGQ9hysaxnbkT\nlqYLIX8dc9kxONzPSPW2DmflX2PfcOvvUXqJtgBOykO5tmaoEN/QrHn5I9BErjqskjyO0//IoQcf\ntyiowieXMeMsV65cKbt37xYRkcOHD0tjY6OsXr1ann76aRERefzxx2Xjxo2TO0pCCJlmxlxZ3nTT\nTbJlyxa55ZZbJAxDufPOO6W9vV2+9KUvSRzHcskll8hVV101FWMlhJBpY8zJsrGxUb71rW+ddfzH\nP/7xpAyIKLZynFyNhRIUBLMVZF5XVMnc1Kr71rgfWSlrY63X3njd2PUF9eYuW6JV3Nva5un1QZKP\njKg0DbBf+agkx33PEQjq7u+FCuQg/avh+CqKZ22BJBkn2cHkKNthvxC2NDBgHr3blSEo3QbXrEKT\nMtxPDTO2VcjEw3RHQghxgJMlIYQ4wNzwWUJmwDTYWZ5uF7LCjvA4enZRduaC9OZipeERYx89eNjY\nWEZt0QLNSS9CoPYQNFBDuRucua+H3nL1CPf3nTJ2lFHKLous0JgkMxQBtgcwRTvjnFxB31+hXnPD\nPai+juFCGFmAkQI+3KwKFfFj5oZPKlxZEkKIA5wsCSHEAcrwWQLmVmNQsmTIcyRTXmLDLcjvRlmd\nBw94HvK4q1Cte2RI5TZeZ8VyzTqplVV6v/LKq8aunKfXweZeyfH0gO8zVd+xhzk+3yDkhldrKlHx\nmVyyWLLOsLzecNzKesIK7XAW9ksv5jRDqaWpxdhl8IbXRvS9Qkq6xBgMz77hUwZXloQQ4gAnS0II\ncYAyfAaD3txKRYO96+v1b1zkEGxtVQDPKKqAyrRQVK9tsVG9tninEgSfD4NcrEDhiLo6/ezqd1xo\n7GpVvdev7lNJHkNwuQTpYeFnyqVBRrRVQs3KGbe6jmHpuLG3JX7rC2pjz3b0tkM5ugqMLoAGZPVQ\nKX0e9GwfOanNyzDwvwTXT3J6/RArt6dUkSeTA1eWhBDiACdLQghxgDJ8BlOrqQd5eEBLd+Wh1iPm\nBnvx2N5wD8qjWRXAIZi8sVm9swWomj440K/jAQ94CLIay5BH0J87D97fd1yo/cp9qJ129I3X9L4F\neEYoCaiJ6xCMj1XK4XiASwH0GnvwY2+9snQPvFX3E98lXD+GKIAwj9seelIA1c7roGo65sRbfdLg\ns/g+8Lhdvm7u15ucTriyJIQQBzhZEkKIA5ThM5gQgqr7+rT02AKoTF+D3GCUjlmNuPALNfBv5wvo\nAVfpXSmnlz/DsWFgdBSChxgkP+Y55+pUUl544TuN3ZTXH8c9u5/Xz1Y10PyM1ETPvC1XVdL6kE+d\nWOMCjzZcx8q/t/qM45oCPNRwFL3eIXylVAAveajvsjqk2ypV2IqIIQoAS8w15FTCS03Px9xwMrlw\nZUkIIQ5wsiSEEAcow2cAWaHE6IU9eHC/sc9fdb6eZPW0TtfbHkjEGP48ogdcIBD9YL92cSz39xnb\nr6hXWoW07Wi2AsjRu4y5zSh3wbvcDrnki/o0R3rfb36jVx+9kJ8RaI+ecwzkD0CqRxlRA0nGfgXG\nsMcgpWsQRO/7+qvUCwH7+0/o+2vL6RbBQj1FKrUK2LC9AeMcgnJ3RXgur06/b2+1cyNxgytLQghx\ngJMlIYQ4QBk+g8lBGbK+Ez3GPnjwgLGXrTjf2BHqYQwOt8uaG7McatD70e5DxsbyZ2159cI2gtSs\nYYw3VPqOrPJkAEpE6wvpQduLQJK/sXeffrQSj14OPNrgNR7sV/k+PDBs7IZGaLAGldW9jNZkWHXc\n9/F8PV6D3O2CqBzuhwSCXqjcvmj5Sv1sTccW1fT69SDVB0t6ThkkfwmaudWjx58yfFLhypIQQhzg\nZEkIIQ5Qhs8S4kil2vGjR4x93ooVeo6kS28UmjlsrAVydLhXvbaL5y80dksD5C1Drnc1ozQY5kvj\nVkCQ0RDN6r0N/2mFfuLNrVrObLD7tFfYA8mZg97cNfAU9/eqBE4C9d8HUO4M0rjF98DHbzWC018T\n7FcuCW5LqBwueirJO/KaA94Ax8sBbCOAlI6t3HO1A9xigZJ4NdiCiMfZoI2MD64sCSHEAU6WhBDi\nAGX4TAad2KBvy5BXHIGXNAHPtQfyLA9yOAfXxOMLoWd3KzQmK0A0eRXKkKGsRg+xh15qdICjeoVz\nfOyZDcfrGlW+trTrtkD/sdNbEHkMMof7VCEg/PABjRqI8/p8TfNU1sNrkgiiAAS2KGJcU4A0FnhP\nNciDPwWl7LpP6lbAwhb1yDe1qi0ljUoY6dHtkIqv39sYPOZRqIHrtRBz9IVMIlxZEkKIA5wsCSHE\nAcrwGYBVTs36Cshn8JKODGmw8sEDh429Yu3Fxq6hNE1AwgXqkR2EyPLXuo8be6iqcnvV0mU6GpC+\nmOuNJdJCqEIeFNUOUb5CCfO8qLcd5bQHJeOWQhm3w6+frqYeltQjHMBgMCKgABXI57Vp9fe65jZj\n56AkWgIV6JMYtje0PLv4nr4bDyIF8vDc9dCMLBrUIPkQvN4FCMAvQLB/AbYCsIJ6NYBIB6wSj43d\nuPSZVPh6CSHEAU6WhBDiAGX4jAYClEEion3wmMrn+SvXGNtvajT2CEhvAZlXbdDA74FAe3znwKve\nXlSvtAeNwQLwYvvgUi7VqZfXA7lt5aeDJ70cgbcdPLshlC3zWkA2j0rcUqVkjtVZrnY1BSqQD1RV\ntg8e0dxqgUrjFaimnkR6/dDX9+ed6Ql+/bXyzO7dehwrpcM1o1if78V9rxv7ZUgyKI7o+S0QodDU\nolsHIchwD5qUDUEuPDYvIxMPV5aEEOIAJ0tCCHGAMnwGkBlLDB7wGkhprMpdLmtAc3evSrJm9HqD\nN7wGkrUyApW+CyrDh0ZUAr/y+kFj53Ig56G5GFZE37NfK7pj1XKsTo4VwCMIIq9C//EQq5nXhuD4\n6DuBBl5xCNsD4HV//XUtO/dytwaKh+BpL0BQegxl1uJI32sIeeXY5/zVw1o2DwPtC3BO4qtHO7C2\nGfT6jfBrOILe/DyUvgtBhnvYNE3trArwZGLgypIQQhzgZEkIIQ5Qhs9gsJlXDWRn4GFFb7X3HVAJ\n7PWolzwET3RolW7Tz9ZBL+8yyPCT3dq8DPOiEyhzhtsFrx8+kHZYPKtTGlQhx0B3aNYVQoS6H+tx\n43nHsmZRehJ6oU5/vCOQtDUs6QZbGjFWOPP1fURYlq0eyrhB0HgCkQJY9y2AiIAcyPxCqLnqUK1N\narBlEmaUwfOtiu5Yst76AJlguLIkhBAHOFkSQogDlOEzGPRtljA/GTzdIchOH6qE++Al9fJ6Dlbi\nxvzuBGu3wZ/QMI9V0EFSggxHJ2y+WAfnwI8X3CwCyYryFfPfsSK556mn/sx4khH1/HtWmTLYcgC5\n2twy39iNBR1jzdorULMA/bjz9focPkjv81aepx+wXiZI6Qi2ECCQvw487DkrqF4/i+/PiumHgZYr\nGmyPSQBk4uHbJYQQBzhZEkKIA5ThMxiUvfUdHcb26zXv28urXKwvqrRraIAGXQVsiKXXrELf8FpV\nbcz1nle3RK8D98rDOdhYa9VaLacWWBIXvNHQWGukXyuDxyUNkm9o0Zz0HDxXpf+0l7+/96jeB9zG\ncahjTGr6uZEhyDVXVS81yLku1Otn6xr0HfuQi28H1wsc1/9EIL0TT4+j134E8tCx+RpuI9gNy/Re\n+F5rVX0u3N5AGKo+MXBlSQghDnCyJIQQByjDZwBZldJzIHtXrLnQ2H69Bqhj1fEAPh1CCbMKBntD\nIy5sNFYA73YC8j+xmmPpZ6vonYUxYDM1QVWY4GGorF7BrQAoizYEzdGG9Q2FJ0+evgY0CEsgrx0r\ntWPJsnIIXmN4Dg+82LWybgNEffrcxUDfdwQyefBUrx6Hd+D76U3b8LMJlt+D941y3vfxmvBTAlsB\nWBneaqZGJhyuLAkhxAFOloQQ4gBl+AwmRsk3rGXKahCQHUIpMaygHaNUg5znBLRxDBIb+33H4MFN\nalAODKp+h7hfAPJv4LjmknuYa23lM0OAOgwuDMGzO6SyuR6C8HOjkjzOa5V3vwDl0SDgPICg7vo6\nleo1UKt1sNWBWxEelFkLcujV13PqCphjbkX4qxmly2q8jpUfD7+RVdguQLWNNQMSKGsnLJQ+qXBl\nSQghDnCyJIQQB7wEo2AJIYSkwpUlIYQ4wMmSEEIc4GRJCCEOcLIkhBAHOFkSQogDnCwJIcQBTpaE\nEOLAlKU7fvWrX5Xdu3eL53myZcsWWb9+/VTdesq4++675ZlnnpEwDOXTn/60dHZ2yubNmyWKImlv\nb5d77rlHCoXC2BeaJZTLZfnIRz4in/3sZ+XKK6+c08/66KOPyv333y+5XE4+97nPyZo1a+bs8w4P\nD8vtt98u/f39UqvV5NZbb5X29na58847RURkzZo1ctddd03vIKeDZArYtWtX8qlPfSpJkiTZu3dv\ncuONN07FbaeUrq6u5M///M+TJEmSU6dOJVdffXXyxS9+MXnssceSJEmSb3zjG8mPfvSj6RzihHPv\nvfcmH/vYx5KHH354Tj/rqVOnkuuuuy4ZHBxMuru7kzvuuGNOP+8Pf/jD5Otf/3qSJEly7Nix5IMf\n/GByyy23JLt3706SJEn++q//Otm5c+d0DnFamBIZ3tXVJddee62IiKxevVr6+/tlaGhojE/NLq64\n4gr51re+JSIiLS0tUiqVZNeuXfL+979fRESuueYa6erqms4hTij79u2TvXv3yvve9z4RkTn9rF1d\nXXLllVdKU1OTdHR0yIXjG0MAAALXSURBVFe+8pU5/bzz5s2Tvr7T7T4GBgakra1NDh8+bNTgXHte\nV6Zksjxx4oTMm6dVYubPny89PT1TcespIwgCaWhoEBGRbdu2yXvf+14plUpGmi1YsGBOPfM//uM/\nyhe/+EXz/7n8rIcOHZJyuSyf+cxnZNOmTdLV1TWnn/fDH/6wHDlyRD7wgQ/ILbfcIps3b5aWlhbz\n9bn2vK5MS4m2ZA6noz/xxBOybds2eeCBB+S6664zx+fSM2/fvl0uvfRSWb58eerX59KznqGvr0++\n/e1vy5EjR+STn/yk9Yxz7XkfeeQRWbp0qfzgBz+Ql156SW699VZpbm42X59rz+vKlEyWHR0dcuKE\n1jk8fvy4tLe3T8Wtp5Qnn3xSvve978n9998vzc3N0tDQIOVyWYrFonR3d0sHdGiczezcuVMOHjwo\nO3fulGPHjkmhUJizzypyeiV12WWXSS6XkxUrVkhjY6MEQTBnn/fZZ5+VDRs2iIjI2rVrpVKpSAi1\nNefa87oyJTL8Pe95j+zYsUNERF544QXp6OiQpqamMT41uxgcHJS7775bvv/970tbW5uIiFx11VXm\nuR9//HHZuHHjdA5xwvjmN78pDz/8sPzkJz+Rj3/84/LZz352zj6riMiGDRvkqaeekjiOpbe3V0ZG\nRub0865cuVJ2794tIiKHDx+WxsZGWb16tTz99NMiMvee15UpK9H29a9/XZ5++mnxPE++/OUvy9q1\na6fitlPG1q1b5b777pNVq1aZY1/72tfkjjvukEqlIkuXLpV/+Id/kDxU5p4L3HfffbJs2TLZsGGD\n3H777XP2WR966CHZtm2biIj8xV/8hXR2ds7Z5x0eHpYtW7bIyZMnJQxD+fznPy/t7e3ypS99SeI4\nlksuuUT+9m//drqHOeWwniUhhDjADB5CCHGAkyUhhDjAyZIQQhzgZEkIIQ5wsiSEEAc4WRJCiAOc\nLAkhxIH/DwfHiFgD+QP1AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f65f6580518>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "kKELirRwZS0s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def process_files(list_files, label):\n",
        "    output = []\n",
        "    for i in list_files:\n",
        "        temp = []\n",
        "        temp.append(i)\n",
        "        l = [0, 0]\n",
        "        l[label] = 1.\n",
        "        temp.append(l)\n",
        "        output.append(temp)\n",
        "    return output\n",
        "\n",
        "#print(process_files(['a','b','c','d'], 0))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Td6PvrvpZS04",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "64c4793f-5305-4eaa-f414-3d23e69a158a"
      },
      "cell_type": "code",
      "source": [
        "#fishing 1, Notfishing 0\n",
        "samples_fishing_list = list_files(\"./fishing_images/fishing/*.jpg\")\n",
        "samples_not_fishing_list = list_files(\"./fishing_images/not_fishing/*.jpg\") + list_files(\"./fishing_images/not_fishing_1/*.jpg\")\n",
        "print(len(samples_fishing_list))\n",
        "print(len(samples_not_fishing_list))\n",
        "samples = process_files(samples_fishing_list, 1) + process_files(samples_not_fishing_list, 0)\n",
        "\n",
        "#img = read_image(samples[0][0])\n",
        "#print(img.shape)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1703\n",
            "1848\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "S2Gvt3L8ZS1E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aae33a90-2514-43a9-9d80-ae77ffaa4964"
      },
      "cell_type": "code",
      "source": [
        "#testing\n",
        "\n",
        "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
        "print(train_samples[1])"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['./fishing_images/not_fishing_1/image_3141.jpg', [1.0, 0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "vwLTdJu3ZS1M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1125
        },
        "outputId": "a838ec34-cfbb-41fc-d67c-f00a72558adc"
      },
      "cell_type": "code",
      "source": [
        "#The execution portion of the code.\n",
        "#save a model\n",
        "\n",
        "model = NvidiaNet(drop_prob = 0.2)\n",
        "model.summary()\n",
        "model.compile(loss='mse', optimizer='adam')\n",
        "\n",
        "\n",
        "sklearn.utils.shuffle(samples)\n",
        "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
        "print(train_samples[1])\n",
        "\n",
        "#Hyperparameters\n",
        "train_generator = generator(train_samples, 16)\n",
        "validation_generator = generator(validation_samples)\n",
        "epoch = 3\n",
        "#end of hyperparameters\n",
        "\n",
        "history = model.fit_generator(train_generator, samples_per_epoch = len(train_samples), validation_data = validation_generator,\\\n",
        "                   nb_val_samples = len(validation_samples), nb_epoch = epoch)\n",
        "model.save(\"model.h5\")\n",
        "print(\"Model Generated\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:15: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=3, strides=(1, 1))`\n",
            "  from ipykernel import kernelapp as app\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:23: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=24, strides=(2, 2))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:28: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=36, strides=(1, 1))`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:36: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=48)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:41: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(kernel_size=(3, 3), filters=64)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:49: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=50)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:52: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=25)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(units=10)`\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:58: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(activation=\"softmax\", units=2)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "cropping2d_10 (Cropping2D)   (None, 100, 100, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_46 (Conv2D)           (None, 98, 98, 3)         84        \n",
            "_________________________________________________________________\n",
            "activation_46 (Activation)   (None, 98, 98, 3)         0         \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 98, 98, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_47 (Conv2D)           (None, 48, 48, 24)        672       \n",
            "_________________________________________________________________\n",
            "activation_47 (Activation)   (None, 48, 48, 24)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_48 (Conv2D)           (None, 46, 46, 36)        7812      \n",
            "_________________________________________________________________\n",
            "activation_48 (Activation)   (None, 46, 46, 36)        0         \n",
            "_________________________________________________________________\n",
            "dropout_20 (Dropout)         (None, 46, 46, 36)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_49 (Conv2D)           (None, 44, 44, 48)        15600     \n",
            "_________________________________________________________________\n",
            "activation_49 (Activation)   (None, 44, 44, 48)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_50 (Conv2D)           (None, 42, 42, 64)        27712     \n",
            "_________________________________________________________________\n",
            "activation_50 (Activation)   (None, 42, 42, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_10 (Flatten)         (None, 112896)            0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 50)                5644850   \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 25)                1275      \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 10)                260       \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 2)                 22        \n",
            "=================================================================\n",
            "Total params: 5,698,287\n",
            "Trainable params: 5,698,287\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "['./fishing_images/fishing/image_1463.jpg', [0, 1.0]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:17: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., steps_per_epoch=2840, epochs=3, validation_steps=711)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2840Epoch 1/3\n",
            "\n",
            "1380/2840 [=============>................] - ETA: 2:20 - loss: 0.4941"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2839/2840 [============================>.] - ETA: 0s - loss: 0.3431711\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2840/2840 [==============================] - 382s 134ms/step - loss: 0.3431 - val_loss: 0.1812\n",
            "Epoch 2/3\n",
            " 569/2840 [=====>........................] - ETA: 3:36 - loss: 0.2020"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2308/2840 [=======================>......] - ETA: 50s - loss: 0.2003"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2840/2840 [==============================] - 379s 133ms/step - loss: 0.2002 - val_loss: 0.1811\n",
            "Epoch 3/3\n",
            " 364/2840 [==>...........................] - ETA: 3:50 - loss: 0.2004"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1799/2840 [==================>...........] - ETA: 1:39 - loss: 0.2001"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "2448/2840 [========================>.....] - ETA: 37s - loss: 0.2004"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "_pWgI_lLZS1U",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(history.history.keys())\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ejquxLIEZS1g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print(train_samples[0])\n",
        "img_list = []\n",
        "name = './data/IMG/' + train_samples[0][0].split('/')[-1]\n",
        "center_image = cv2.imread(name)\n",
        "left_image = read_image(train_samples[0][1])\n",
        "right_image = read_image(train_samples[0][2])\n",
        "img_list.append(center_image)\n",
        "img_list.append(left_image)\n",
        "img_list.append(right_image)\n",
        "\n",
        "flip_output = horizontal_flip(center_image, 0)\n",
        "img_list.append(flip_output[0])\n",
        "flip_output = horizontal_flip(left_image, 0)\n",
        "img_list.append(flip_output[0])\n",
        "flip_output = horizontal_flip(right_image, 0)\n",
        "img_list.append(flip_output[0])\n",
        "\n",
        "fig = plt.figure(figsize=(75, 150))\n",
        "# plt.imshow(center_image)\n",
        "# plt.imshow(flip_image)\n",
        "columns = 3\n",
        "rows = 2\n",
        "w=100\n",
        "h=100\n",
        "for i in range(1, columns*rows +1):\n",
        "    img = np.random.randint(10, size=(h,w))\n",
        "    fig.add_subplot(rows, columns, i)\n",
        "    plt.imshow(img_list[i-1])\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TuAIqF6OZS1o",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GhQhIugvZS10",
        "colab_type": "code",
        "colab": {},
        "outputId": "85511932-f8c0-438b-c022-04aa5b9e72e3"
      },
      "cell_type": "code",
      "source": [
        "def load_trained_model(weights_path):\n",
        "    model = NvidiaNet()\n",
        "    model.load_weights(weights_path)\n",
        "    return model\n",
        "\n",
        "\n",
        "#fishing = load_trained_model(\"./model.h5\")\n",
        "\n",
        "#score = fishing.evaluate(x_test, y_test, batch_size=32)\n",
        "img = read_image(samples[-1][0])\n",
        "#prediction = fishing.predict(np.expand_dims(img, axis=0))\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "print(prediction)\n",
        "   "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "integer argument expected, got float",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-e18c0aa7ed45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#score = fishing.evaluate(x_test, y_test, batch_size=32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;31m#prediction = fishing.predict(np.expand_dims(img, axis=0))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-e227b74852b0>\u001b[0m in \u001b[0;36mread_image\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPIL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_square\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mANTIALIAS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m#open_cv_image = numpy.array(pil_image)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-e227b74852b0>\u001b[0m in \u001b[0;36mmake_square\u001b[0;34m(im, min_size, fill_color)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mnew_im\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfill_color\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0mnew_im\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_im\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/home/carnd/anaconda3/envs/carnd-term1/lib/python3.5/site-packages/PIL/Image.py\u001b[0m in \u001b[0;36mpaste\u001b[0;34m(self, im, box, mask)\u001b[0m\n\u001b[1;32m   1344\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1345\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1346\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpaste\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1348\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: integer argument expected, got float"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "eXdpUE46ZS18",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WDx0w3NzZS2I",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}